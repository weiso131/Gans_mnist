{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, RandomSampler\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "\n",
    "from model import Mnist_classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get mnist data\n",
    "\n",
    "batch = 128\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "mnist = datasets.MNIST(root='C:/Users/weiso131/Desktop/Gans_mnist/data', train=True, download=True, transform=transform)\n",
    "\n",
    "indice = torch.randperm(len(mnist))\n",
    "\n",
    "train_sampler = RandomSampler(indice[:int(0.9 * len(indice))])\n",
    "val_sampler = RandomSampler(indice[int(0.9 * len(indice)):int(0.95 * len(indice))])\n",
    "test_sampler = RandomSampler(indice[int(0.95 * len(indice)):])\n",
    "\n",
    "train_dataloader = DataLoader(mnist, batch_size=batch, sampler=train_sampler)\n",
    "val_dataloader = DataLoader(mnist, batch_size=batch, sampler=val_sampler)\n",
    "test_dataloader = DataLoader(mnist, batch_size=batch, sampler=test_sampler)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use GPU\n"
     ]
    }
   ],
   "source": [
    "model = Mnist_classifer()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.001)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "use_gpu = torch.cuda.is_available()\n",
    "\n",
    "if (use_gpu):\n",
    "    print(\"use GPU\")\n",
    "    model = model.to(device=\"cuda\", dtype=torch.float32)\n",
    "    loss_function = loss_function.to(device=\"cuda\", dtype=torch.float32)\n",
    "\n",
    "epoch = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, loss_function, dataloader, use_gpu : bool):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_acc = 0\n",
    "    count = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in dataloader:\n",
    "            count += 1\n",
    "            if (use_gpu):\n",
    "                x = x.to(device=\"cuda\", dtype=torch.float32)\n",
    "                y = y.to(device=\"cuda\", dtype=torch.int64)\n",
    "            #計算\n",
    "            predict = model(x)\n",
    "            \n",
    "            \n",
    "\n",
    "            #計算loss\n",
    "            loss =  loss_function(predict, y)     \n",
    "            val_loss += loss.item()\n",
    "            \n",
    "            #計算acc\n",
    "            topk, top_class = predict.topk(1, dim=1)\n",
    "            y = y.view(top_class.shape)\n",
    "            val_acc += int((top_class == y).sum()) / len(y)\n",
    "    return val_loss / count, val_acc / count\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_val_loss = 1e9\n",
    "\n",
    "for i in range(epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    count = 0\n",
    "    \n",
    "    for x, y in train_dataloader:\n",
    "        count += 1\n",
    "        optimizer.zero_grad()\n",
    "        if (use_gpu):\n",
    "            x = x.to(device=\"cuda\", dtype=torch.float32)\n",
    "            y = y.to(device=\"cuda\", dtype=torch.int64)\n",
    "        #計算\n",
    "        predict = model(x)\n",
    "        \n",
    "        #計算loss\n",
    "        loss =  loss_function(predict, y)     \n",
    "        train_loss += loss.item()\n",
    "\n",
    "        #計算acc\n",
    "        topk, top_class = predict.topk(1, dim=1)\n",
    "        y = y.view(top_class.shape)\n",
    "        \n",
    "        train_acc += int((top_class == y).sum()) / len(y)\n",
    "        \n",
    "        #反向傳播\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    train_loss, train_acc = train_loss / count , train_acc / count\n",
    "    val_loss, val_acc = validate(model, loss_function, val_dataloader, use_gpu)\n",
    "    #儲存最佳模型\n",
    "    if (val_loss < min_val_loss):\n",
    "        min_val_loss = val_loss\n",
    "        checkpoint = model.state_dict()\n",
    "        torch.save(checkpoint, \"checkpoint.pth\")\n",
    "        print(\"save model\")\n",
    "        \n",
    "    print(f\"train loss: {train_loss}, train acc: {train_acc}, val_loss: {val_loss}, val_acc: {val_acc}\")\n",
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 0.002598424886329486, test acc: 0.9990928613744076\n"
     ]
    }
   ],
   "source": [
    "checkpoint = torch.load(\"checkpoint.pth\")\n",
    "model.load_state_dict(checkpoint)\n",
    "\n",
    "test_loss, test_acc = validate(model, loss_function, train_dataloader, use_gpu)\n",
    "print(f\"test loss: {test_loss}, test acc: {test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
